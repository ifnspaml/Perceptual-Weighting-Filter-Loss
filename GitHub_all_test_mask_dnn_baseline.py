#####################################################################################
# GitHub_all_test_mask_dnn_baseline -
# Test stage for BASELINE mask-based DNN, generates the magnitude of FFT coeff. for
# white- and black-box measurements.
# Given data:
#       Input Data: y_norm
#       Auxiliary input: y (noisy speech)
#       Auxiliary input: s (clean speech)
#       Auxiliary input: n (noise speech)
# Output data:
#       s_hat  -> y_norm to generate mask and y as auxiliray input;
#       s_tilt -> y_norm to generate mask and s as auxiliray input;
#       n_tilt -> y_norm to generate mask and n as auxiliray input;
#
# Technische Universit√§t Braunschweig
# Institute for Communications Technology (IfN)
# Schleinitzstrasse 22
# 38106 Braunschweig
# Germany
# 2019 - 05 - 23
# (c) Ziyue Zhao
#
# Use is permitted for any scientific purpose when citing the paper:
# Z. Zhao, S. Elshamy, and T. Fingscheidt, "A Perceptual Weighting Filter
# Loss for DNN Training in Speech Enhancement", arXiv preprint arXiv:
# 1905.09754.
#####################################################################################

import numpy as np
np.random.seed(1337)  # for reproducibility
from numpy import random
import os
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import *
from tensorflow.keras import backend as K
import tensorflow.keras.optimizers as Adam
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger, TensorBoard, LearningRateScheduler
import scipy.io as sio


def reshapeDataMatrix(data_matrix, look_backward=1, look_forward=2):
    new_dim_len = look_backward + look_forward + 1
    data_matrix_out = np.zeros((data_matrix.shape[0], data_matrix.shape[1], new_dim_len))
    for i in range(0, data_matrix.shape[0]):
        for j in range(-look_backward, look_forward + 1):
            if i < look_backward:
                idx = max(i + j, 0)
            elif i >= data_matrix.shape[0] - look_forward:
                idx = min(i + j, data_matrix.shape[0] - 1)
            else:
                idx = i + j
            data_matrix_out[i, :, j + look_backward] = data_matrix[idx, :]

    return data_matrix_out

#####################################################################################
# 0. Settings
#####################################################################################

# Define string array for all test SNRs
SNR_situ_array = ["-21","-26","-31","-36","-41","-46"] #

# Loop for all test SNRs
for k_snr in range(0, len(SNR_situ_array)):

    # Settings
    SNR_situ = SNR_situ_array[k_snr]
    noi_situ_model_str = "6snrs"
    fram_length = 129
    n1 = 1024
    n2 = 512
    n3 = 512
    drop_out=0.2

    LOOK_BACKWARD = 2
    LOOK_FORWARD = 2
    INPUT_SHAPE = (fram_length*(LOOK_BACKWARD + 1 + LOOK_FORWARD),)
    INPUT_SHAPE2 = (fram_length,)


    #####################################################################################
    # 1. Model define
    #####################################################################################
    input_img = Input(shape=(INPUT_SHAPE))
    auxiliary_input = Input(shape=(INPUT_SHAPE2))
    wfac_input = Input(shape=(INPUT_SHAPE2))  # weighting factors for frequency bins energy normalization in loss

    d1 = Dense(n1)(input_img)
    d1 =BatchNormalization()(d1)
    d1 = LeakyReLU(0.2)(d1)
    d1 =Dropout(0.2)(d1)

    d2 = Dense(n2)(d1)
    d2 =BatchNormalization()(d2)
    d2 = LeakyReLU(0.2)(d2)
    d2=Dropout(0.2)(d2)

    d3 = Dense(n3)(d2)
    d3 =BatchNormalization()(d3)
    d3 = LeakyReLU(0.2)(d3)
    d3 =Dropout(0.2)(d3)

    m1 = Add()([d2, d3])
    d4 = Dense(n2)(m1)
    d4 =BatchNormalization()(d4)
    d4 = LeakyReLU(0.2)(d4)
    d4 =Dropout(0.2)(d4)

    m2 = Add()([d2, d3, d4])
    d5 = Dense(256)(m2)
    d5 =BatchNormalization()(d5)
    d5 = LeakyReLU(0.2)(d5)
    d5 =Dropout(0.2)(d5)

    d6 =BatchNormalization()(d5)
    mask= Dense(129,activation='sigmoid')(d6)

    decoded= Multiply()([mask,auxiliary_input])

    # Weighting factors for frequency bins in loss (energy normalization)
    decoded_wgh_factor = Multiply()([decoded, wfac_input])

    model = Model(inputs=[input_img, auxiliary_input, wfac_input], outputs=decoded_wgh_factor)
    model.summary()

    # Settings
    nb_epochs = 100
    batch_size = 128
    learning_rate = 5e-4
    adam_wn = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=1e-08)
    model.compile(optimizer=adam_wn, loss='mean_squared_error', metrics=['accuracy'])
    model.load_weights("./training results/mask_dnn_baseline_" + noi_situ_model_str + "_weights.h5")

    #####################################################################################
    # 2. load data
    #####################################################################################

    # Load Input Data: y_norm
    print('> Loading input data: y_norm... ')
    mat_input ="./test data/test_input_y_abs_snr_" + SNR_situ + "_model_" + noi_situ_model_str + "_test_data.mat"
    mat_input = os.path.normcase(mat_input)
    x_test_noisy = sio.loadmat(mat_input)
    x_test_noisy = x_test_noisy['test_input_y']
    x_test_noisy = np.array(x_test_noisy)
    print('  >> Reshaping test input data... ')
    x_test_noisy = reshapeDataMatrix(x_test_noisy, look_backward=LOOK_BACKWARD, look_forward=LOOK_FORWARD)
    print(x_test_noisy.shape)
    x_test_y_norm = np.reshape(x_test_noisy, (x_test_noisy.shape[0], fram_length*(LOOK_BACKWARD + 1 + LOOK_FORWARD)),order='F')
    print('     Input data y_norm shape: %s' % str(x_test_y_norm.shape))

    # load auxiliary input: y
    print('> Loading auxiliary input data: y... ')
    mat_input_aux_y ="./test data/test_input_abs_unnorm_snr_" + SNR_situ + "_model_" + noi_situ_model_str + "_test_data.mat"
    mat_input_aux_y = os.path.normcase(mat_input_aux_y)
    x_test_noisy_aux_y = sio.loadmat(mat_input_aux_y)
    x_test_noisy_aux_y = x_test_noisy_aux_y['test_input_abs_unnorm']
    x_test_y = np.array(x_test_noisy_aux_y)
    print('     Input data y shape: %s' % str(x_test_y.shape))

    # load auxiliary input: s
    print('> Loading auxiliary input data: s... ')
    mat_input_aux ="./test data/test_input_s_snr_" + SNR_situ + "_model_" + noi_situ_model_str + "_test_data.mat"
    mat_input_aux = os.path.normcase(mat_input_aux)
    x_test_noisy_aux = sio.loadmat(mat_input_aux)
    x_test_noisy_aux = x_test_noisy_aux['test_input_s']
    x_test_s = np.array(x_test_noisy_aux)
    print('     Input data s shape: %s' % str(x_test_s.shape))

    # load auxiliary input: n
    print('> Loading auxiliary input data: n... ')
    mat_input_aux_n ="./test data/test_input_n_snr_" + SNR_situ + "_model_" + noi_situ_model_str + "_test_data.mat"
    mat_input_aux_n = os.path.normcase(mat_input_aux_n)
    x_test_noisy_aux_n = sio.loadmat(mat_input_aux_n)
    x_test_noisy_aux_n = x_test_noisy_aux_n['test_input_n']
    x_test_n = np.array(x_test_noisy_aux_n)
    print('     Input data n shape: %s' % str(x_test_n.shape))

    # Energy normalization as ALL ONES
    x_test_wfac_ones = np.ones_like(x_test_noisy_aux)


    #####################################################################################
    # 3. predict model and save results
    #####################################################################################
    predicted_s_hat = model.predict([x_test_y_norm,x_test_y,x_test_wfac_ones])
    print(predicted_s_hat.shape)
    recon_file = "./test results/mask_dnn_baseline_s_hat_snr_" + SNR_situ + "_model_" + noi_situ_model_str + "_test_data.mat"
    recon_file = os.path.normcase(recon_file)
    sio.savemat(recon_file, {'test_s_hat':predicted_s_hat})

    predicted_s_tilt = model.predict([x_test_y_norm,x_test_s,x_test_wfac_ones])
    print(predicted_s_tilt.shape)
    recon_file = "./test results/mask_dnn_baseline_s_tilt_snr_" + SNR_situ + "_model_" + noi_situ_model_str + "_test_data.mat"
    recon_file = os.path.normcase(recon_file)
    sio.savemat(recon_file, {'test_s_tilt':predicted_s_tilt})

    predicted_n_tilt = model.predict([x_test_y_norm,x_test_n,x_test_wfac_ones])
    print(predicted_n_tilt.shape)
    recon_file = "./test results/mask_dnn_baseline_n_tilt_snr_" + SNR_situ + "_model_" + noi_situ_model_str + "_test_data.mat"
    recon_file = os.path.normcase(recon_file)
    sio.savemat(recon_file, {'test_n_tilt':predicted_n_tilt})

    print('>>> Finishing of SNR: ' + SNR_situ + '...')

